{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2766eba9-c1d8-4798-bf42-3f05bceeba81",
   "metadata": {},
   "source": [
    "CO4: Apply Principal Component Analysis (PCA) to reduce dimensionality on real-world datasets belonging to health/finance   6 Hours   \n",
    "\n",
    "1. Dimensionality reduction techniques\n",
    "2. Principal Component Analysis (PCA)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc92e72ecc72ed33",
   "metadata": {},
   "source": [
    "#### Feature Selection  \n",
    "Reduces Overfitting: Less redundant data means less opportunity to make decisions based on noise.  \n",
    "Improves Accuracy: Less misleading data means modeling accuracy improves.  \n",
    "Reduces Training Time: Less data means that algorithms train faster.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f1c1cc-7e7c-4805-bce8-43aedae30866",
   "metadata": {},
   "source": [
    "#### Popular feature reduction techniques   \n",
    "- **Principal Component Analysis (PCA)** for reducing the dimensionality of high-dimensional data while preserving most of the important information.    \n",
    "- **Linear Discriminant Analysis (LDA)** for classification problems with many features but only a few samples.    \n",
    "- **t-Distributed Stochastic Neighbor Embedding (t-SNE)** for visualizing complex patterns in high-dimensional data.     \n",
    "- **Independent Component Analysis (ICA)** for extracting meaningful features from complex signals, such as images and audio.   \n",
    "- **Non-negative Matrix Factorization (NMF)** for decomposing a non-negative matrix into two low-rank non-negative matrices.\n",
    "\n",
    "Use with caution, as they can sometimes lead to loss of information or introduce bias into the model. Evaluate the performance of a model after applying a feature reduction technique and compare it with the performance of the original model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543a3a9e-972f-402d-bd11-b1ac3986b11d",
   "metadata": {},
   "source": [
    "##### Pre-processing   \n",
    "1. Add attributes to your data   \n",
    "- <u>Dummy Attributes</u>: Categorical attributes can be converted into n-binary attributes, where n is the number of categories (or levels) that the attribute has.  \n",
    "- <u>Transformed Attribute</u>: A transformed variation of an attribute can be added to the dataset in order to allow a linear method to exploit possible linear and non-linear relationships between attributes. Simple transforms like log, square and square root can be used.  \n",
    "- <u>Missing Data</u>: Attributes with missing data can have that missing data imputed using a reliable method, such as k-nearest neighbors.   \n",
    "\n",
    "2. Remove attributes from your data.   \n",
    "\n",
    "- Project into lower dimensional spaces, but still characterize the inherent relationships in the data. PCA.   \n",
    "- Changed into a higher dimension, we may identify outliers more easily.   \n",
    "- Pairwise attributes with high correlation can be identified and the most correlated attributes can be removed from the data.  \n",
    "    [Variance Threshold](https://scikit-learn.org/stable/modules/feature_selection.html)\n",
    "        \n",
    "3. Transform attributes in your data.  \n",
    "- <u>Centering</u>: Transform the data so that it has a mean of zero and a standard deviation of one. This is typically called data standardization.    \n",
    "- <u>Scaling</u>: A standard scaling transformation is to map the data from the original scale to a scale between zero and one. This is typically called data normalization.  \n",
    "- <u>Remove Skew</u>: Skewed data is data that has a distribution that is pushed to one side or the other (larger or smaller values) rather than being normally distributed. Some methods assume normally distributed data and can perform better if the skew is removed. Try replacing the attribute with the log, square root or inverse of the values.  \n",
    "- <u>Box-Cox</u>: A Box-Cox transform or family of transforms can be used to reliably adjust data to remove skew.  \n",
    "- <u>Binning</u>: Numeric data can be made discrete by grouping values into bins. This is typically called data discretization. This process can be performed manually, although is more reliable if performed systematically and automatically using a heuristic that makes sense in the domain.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7366995e-3c9f-4fbb-bd4a-a06c907557e7",
   "metadata": {},
   "source": [
    "##### Variance Threshold Example   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07909e1d-fe86-457b-81e5-cd18b0f224ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data\n",
      "[[0, 0, 1], [0, 1, 0], [1, 0, 0], [0, 1, 1], [0, 1, 0], [0, 1, 1]]\n",
      "\n",
      "After applying variance threshold\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X = [[0, 0, 1], [0, 1, 0], [1, 0, 0], [0, 1, 1], [0, 1, 0], [0, 1, 1]]\n",
    "sel = VarianceThreshold(threshold=(.8 * (1 - .8)))\n",
    "print(f\"Original Data\\n{X}\\n\")\n",
    "print(\"After applying variance threshold\")\n",
    "sel.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff36976-98ed-495d-81cc-7d88a446d9d9",
   "metadata": {},
   "source": [
    "#### Task   \n",
    "Take student data with age, height, weight, shoulder, waist, shoe size, and collar size.   \n",
    "Apply various variance threshold and see what columns are excluded.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b805515-e3b9-4781-84b4-0db4c47f17db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data\n",
      "[[0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 1]\n",
      " [0 1 0]\n",
      " [0 1 1]]\n",
      "\n",
      "After applying variance threshold\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "plt.figure(figsize=(2,2))\n",
    "X = np.array([[0, 0, 1], [0, 1, 0], [1, 0, 0], [0, 1, 1], [0, 1, 0], [0, 1, 1]])\n",
    "\n",
    "ax = sns.heatmap(X, linewidth=0.5, cbar=False)\n",
    "plt.show()\n",
    "\n",
    "sel = VarianceThreshold(threshold=(.8 * (1 - .8)))\n",
    "print(f\"Original Data\\n{X}\\n\")\n",
    "print(\"After applying variance threshold\")\n",
    "sel.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593b6a310d97b3e3",
   "metadata": {},
   "source": [
    "#### Principal Component Analysis   \n",
    "The most popular techniques to reduce the dimension of input data.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff2e987-60ab-41a8-b65c-dae0062f7463",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "As dimension increases, many interesting and counterintuitive phenomena arise. The “**Curse of Dimensionality**” is a term invented by mathematician Richard Bellman that refers to all these surprising effects.  \n",
    "\n",
    "- The number of input variables or features for a dataset is referred to as its dimensionality.\n",
    "- Dimensionality reduction refers to techniques that reduce the number of input variables in a dataset.\n",
    "- More input features often make a predictive modeling task more challenging to model, more generally referred to as the curse of dimensionality.\n",
    "- Reduction in dimension simplify a classification or regression dataset in order to better fit a predictive model.\n",
    "\n",
    "1. Large numbers of input features can cause poor performance for machine learning algorithms.  \n",
    "2. Dimensionality reduction is a general field of study concerned with reducing the number of input features.  \n",
    "3. Dimensionality reduction methods include feature selection, linear algebra methods, projection methods, and autoencoders.    \n",
    "4. Dimensionality reduction is performed on data prior to modeling. It might be performed after data cleaning and data scaling and before training a predictive model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e2a824-ae2f-436a-ad54-a0570cc42460",
   "metadata": {},
   "source": [
    "<u>Feature projection</u> - retain the features that represents the **essence** of the data.  \n",
    "Any new data that is fed to the model in the future when making predictions,  \n",
    "such as test dataset and new datasets, must also be projected using the same technique.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec352fe1-4e6b-4235-934a-558f59d588d1",
   "metadata": {},
   "source": [
    "#### Manually Calculate Principal Component Analysis   \n",
    "A is a  n X m matrix    \n",
    "```\n",
    "   [a11, a12\n",
    "    a21, a22\n",
    "    a31, a32]\n",
    "```   \n",
    "Calculate the mean value of each column   \n",
    "```\n",
    "   M(m11, m12) = [(a11 + a21 + a31)/3, \n",
    "                  (a12 + a22 + a32)/3]\n",
    "```\n",
    "Center the values in each column by subtracting the mean column value   \n",
    "```\n",
    "   C = A - M\n",
    "```  \n",
    "Calculate the covariance matrix of the centered matrix C. \n",
    "```\n",
    "   V = cov(C)\n",
    "```   \n",
    "calculate the eigen-decomposition of the covariance matrix V. This results in a list of eigenvalues and a list of eigenvectors.\n",
    "```\n",
    "   values, vectors = eig(v)\n",
    "```\n",
    "If all eigen-values have a similar value, then the existing representation may already be reasonably compressed \n",
    "and the projection may offer little.  \n",
    "If there are eigenvalues close to zero, they represent components or axes of B that may be discarded.   \n",
    "```\n",
    "   B = select(values, vectors)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d03e0b-7b7e-4337-9438-851dc122e20f",
   "metadata": {},
   "source": [
    "[Refer](https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation) for cross validation.     \n",
    "[Refer](https://www.mathsisfun.com/algebra/eigenvalue.html) for eigen vector and eigen value.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ede9636c-561c-4cbc-8611-963a798e87f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "sns.set()\n",
    "\n",
    "from numpy import array\n",
    "from numpy import mean\n",
    "from numpy import cov\n",
    "from numpy.linalg import eig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87e70568-8918-4999-9ba8-76b66086c22a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A = array([[1, 2],\n",
      "       [3, 4],\n",
      "       [5, 6]])\n",
      "\n",
      "mean of A,\n",
      " M = array([3., 4.])\n",
      "\n",
      " cemtered columns\n",
      " C = array([[-2., -2.],\n",
      "       [ 0.,  0.],\n",
      "       [ 2.,  2.]])\n",
      "\n",
      "covariance\n",
      " V = array([[4., 4.],\n",
      "       [4., 4.]])\n",
      "\n",
      " eigendecomposition\n",
      " vectors = array([[ 0.70710678, -0.70710678],\n",
      "       [ 0.70710678,  0.70710678]])\n",
      "\n",
      " eigendecomposition\n",
      " values = array([8., 0.])\n",
      "\n",
      "project data \n",
      "[[-2.82842712  0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 2.82842712  0.        ]] \n"
     ]
    }
   ],
   "source": [
    "# define a matrix\n",
    "A = array([[1, 2], [3, 4], [5, 6]])\n",
    "print(f'{A = }\\n')\n",
    "\n",
    "# calculate the mean of each column\n",
    "M = mean(A.T, axis=1)\n",
    "print(f'mean of A,\\n {M = }\\n')\n",
    "\n",
    "# center columns by subtracting column means\n",
    "C = A - M\n",
    "print(f\" cemtered columns\\n {C = }\\n\")\n",
    "\n",
    "# calculate covar iance matrix of centered matrix\n",
    "V = cov(C.T)\n",
    "print(f\"covariance\\n {V = }\\n\")\n",
    "\n",
    "# eigendecomposition of covariance matrix\n",
    "values, vectors = eig(V)\n",
    "print(f\" eigendecomposition\\n {vectors = }\\n\")\n",
    "print(f\" eigendecomposition\\n {values = }\\n\")\n",
    "\n",
    "# project data\n",
    "P = vectors.T.dot(C.T)\n",
    "print(f\"project data \\n{P.T} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265c766b-fbea-453c-a83e-e2025cd248a2",
   "metadata": {},
   "source": [
    "PCA is a **unsupervised linear** dimensionality reduction technique and won't work with non-linear data.   \n",
    "KernelPCA (or the kernel trick) precisely addresses this limitation of PCA. \n",
    "- Project the data to another high-dimensional space using a kernel function, where the data becomes linearly representable. Sklearn provides a KernelPCA wrapper, supporting many popularly used kernel functions.\n",
    "- Apply the standard PCA algorithm to the transformed data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c607af-a172-4f3c-a95d-bc4e191937dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel('../Data/BSc23_Student_Data.xlsx')\n",
    "df = df.dropna()\n",
    "A_ = df[['Height_cm', 'Weight_Kg', 'Shoe_Size', 'Shoulder_cm',\n",
    "       'Waist_cm']].values\n",
    "A_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "263f1197-c6c8-4280-8634-ddfdee2d920d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " eigendecomposition\n",
      " vectors_ = array([[-2.33596832e-01, -7.55089807e-01, -5.99357896e-01,\n",
      "        -9.57287360e-02,  8.29338628e-02],\n",
      "       [-8.29308914e-01,  4.22026673e-01, -2.41098292e-01,\n",
      "        -3.28256966e-02, -2.73741301e-01],\n",
      "       [-4.42071628e-02, -6.33452086e-02, -6.53349146e-02,\n",
      "         9.94543520e-01, -2.54489218e-02],\n",
      "       [-2.03961083e-01,  1.98281803e-01, -4.18695358e-02,\n",
      "         2.53120371e-02,  9.57439526e-01],\n",
      "       [-4.62736263e-01, -4.56513507e-01,  7.59355001e-01,\n",
      "         9.85344189e-04,  2.91475669e-02]])\n",
      "  [484.71745025 108.13893791  98.35166881   0.97245863  35.15082689]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "M_ = mean(A_.T, axis=1)\n",
    "C_ = A_ - M_\n",
    "V_ = cov(C_.T)\n",
    "values_, vectors_ = eig(V_)\n",
    "print(f\" eigendecomposition\\n {vectors_ = }\\n  {values_}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef74ac74-5327-4e44-b19f-3b91d4cb6595",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " eigendecomposition\n",
      " values_ = array([484.71745025, 108.13893791,  98.35166881,   0.97245863,\n",
      "        35.15082689])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\" eigendecomposition\\n {values_ = }\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71975551-a829-411b-bc5f-3bf3d2e98097",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "P_ = vectors_.T.dot(C_.T)\n",
    "\n",
    "print(f\"project data \\n{P_.T} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "434b734c-4f50-4f7f-b397-b6f780a848ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55d3182b-3cc5-420c-8159-9fe23a572702",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>PCA(n_components=5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;PCA<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.decomposition.PCA.html\">?<span>Documentation for PCA</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>PCA(n_components=5)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "PCA(n_components=5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=5)\n",
    "pca.fit(A_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7442fdfa-0777-4780-a19b-b84ada35c725",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.33596832e-01  8.29308914e-01  4.42071628e-02  2.03961083e-01\n",
      "   4.62736263e-01]\n",
      " [-7.55089807e-01  4.22026673e-01 -6.33452086e-02  1.98281803e-01\n",
      "  -4.56513507e-01]\n",
      " [ 5.99357896e-01  2.41098292e-01  6.53349146e-02  4.18695358e-02\n",
      "  -7.59355001e-01]\n",
      " [ 8.29338628e-02 -2.73741301e-01 -2.54489218e-02  9.57439526e-01\n",
      "   2.91475669e-02]\n",
      " [ 9.57287360e-02  3.28256966e-02 -9.94543520e-01 -2.53120371e-02\n",
      "  -9.85344189e-04]]\n"
     ]
    }
   ],
   "source": [
    "print(pca.components_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0df624f-75cd-47ed-8428-2e4d0583b149",
   "metadata": {},
   "source": [
    "#### Variance Explained   \n",
    "_Variance explained_ refers to the proportion of the dataset's total variation attributed to each principal component.   \n",
    "In PCA, components are ordered by the amount of variance they explain, from the greatest to the least.   \n",
    "\n",
    "_variance_ in _Variance Explained_ refers to how much the data spreads out around the mean,  \n",
    "and the “explained” part refers to how much of this spread is captured by each principal component.  \n",
    "The first principal component is aligned with the greatest variance, and captures the most spread of the data.  \n",
    "The second principal component captures the most variance while being orthogonal to the first, and so on for subsequent components.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7217f0ab-aaf8-4e7a-a159-8040e1953ac9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[484.71745025 108.13893791  98.35166881  35.15082689   0.97245863]\n"
     ]
    }
   ],
   "source": [
    "print(pca.explained_variance_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108d3f2c-5e43-4e91-8d7e-efc116264dbe",
   "metadata": {
    "tags": []
   },
   "source": [
    "PC1 = ϕ11 X1 + ϕ21 X2 + … + ϕp1 Xp   \n",
    "PC1: The first principal component.  \n",
    "X1, X2, …, Xp: The original features of the dataset.  \n",
    "ϕ11, ϕ21, …, ϕp1: The weights assigned to each original feature for the first principal component.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c94728b2ac1ecf",
   "metadata": {},
   "source": [
    "[Case for Feature Reduction](https://survey.stackoverflow.co/2023/)   \n",
    "##### Stack Overflow Developer Survey.     \n",
    "\"In May 2023 over 90,000 developers responded to our annual survey about    \n",
    "how they learn and level up,   \n",
    "which tools they're using,   \n",
    "and which ones they want.\"   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb385e5f9a2bc05",
   "metadata": {},
   "source": [
    "#### Data Preparation for ML\n",
    "1. Data Cleaning to delete duplicate rows are redundant columns\n",
    "2. Outlier Detection and removal\n",
    "3. Missing Value identification and imputation\n",
    "4. Feature Selection with statistics and models\n",
    "5. Feature Importance with models\n",
    "6. Data Transforms to change data scales, types, and distributions\n",
    "7. Dimensionality Reduction to create low-dimensional projections\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
