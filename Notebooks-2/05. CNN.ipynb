{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cd4b42b6a4e608e",
   "metadata": {},
   "source": [
    "#### CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ec162e5b19fc20",
   "metadata": {},
   "source": [
    "CO5: Apply convolutional neural networks for classification \t\t\t\t\t9 Hours   \n",
    "1. Introduction to CNN: Difference between CNN and MLP; \n",
    "2. Layers in CNN   \n",
    "3. Convolution, \n",
    "4. Pooling, \n",
    "5. BatchNorm, \n",
    "6. Dropout, \n",
    "7. Activation, \n",
    "8. Dense Layers, \n",
    "9. Loss Functions, \n",
    "10. Standard CNN models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da227ef69456fc34",
   "metadata": {},
   "source": [
    "#### MLP: Mutlilayer Perceptron   \n",
    "MLP is modern feedforward artificial neural network, consisting of fully connected neurons with a nonlinear activation function, organized in at least three layers.  \n",
    "\n",
    "Each new layer is a set of non-linear functions of a weighted sum of all outputs(fully connected) from the prior one. \n",
    "\n",
    "Modern feedforward networks are trained using the backpropagation method.  \n",
    "\n",
    "#### Layers     \n",
    "The core building block of neural networks is the layer, a filter for data. Some data goes in, and comes out in a more useful form.    \n",
    "Layers are **functions** with a known mathematical structure that can be reused and have trainable variables. \n",
    "\n",
    "Layers extract representations out of the data fed into them, representations that are more meaningful for the problem at hand.  \n",
    "Most of deep learning consists of chaining together simple layers that will implement a form of progressive data distillation.  \n",
    "A deep-learning model is like a sieve for data processing, made of a succession of increasingly refined data filters — the layers.  \n",
    "The pseudo neurons are collected into layers, and the outputs of one layer become the inputs of the next in the sequence.   \n",
    "\n",
    "#### Convolutional Neural Network (CNN)      \n",
    "CNN or ConvNets are most commonly used in computer vision. Given a series of images or videos from the real world, with the utilization of CNN, the AI system learns to automatically extract the features of these inputs to complete a specific task, e.g., image classification, face authentication, and image semantic segmentation.  \n",
    "Different from fully connected layers in MLPs, in CNN models, one or multiple convolution layers extract the simple features from input by executing convolution operations. Each layer is a set of nonlinear functions of weighted sums at different coordinates of spatially nearby subsets of outputs from the prior layer, which allows the weights to be reused.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772f6228c625b596",
   "metadata": {},
   "source": [
    "#### Batches and Epochs   \n",
    "An epoch represents one complete pass through the entire training dataset. During an epoch, the model processes all available training samples, computes predictions, calculates the loss, and updates its weights based on the optimization algorithm.  \n",
    "Training Process: The model iterates over the entire dataset multiple times, for several epochs, to learn and improve its performance.  \n",
    "Steps per Epoch: Dividing a large dataset into smaller batches allows the model to update its weights more frequently during each epoch. The steps_per_epoch parameter in Keras specifies how many batches (steps) to process before declaring an epoch finished 1.\n",
    "Remember, each epoch contributes to the model’s learning process, and the goal is to find the optimal set of weights that minimizes the loss function. So, when you see a neural network training for a certain number of epochs, it means it’s going through the entire dataset that many times! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2aab88aced6a85",
   "metadata": {},
   "source": [
    "#### PyTorch and TensorFlow   \n",
    "For the general ML models, we used ScikitLearn.\n",
    "For the deep learning models, we have \n",
    "- PyTorch from pytorch.org, an open-source deep learning framework. Part of Colab.     \n",
    "- TensorFlow from tensorflow.org, developed by Google Brain team. TPU is an ASIC   \n",
    "- Keras from Google is a wrapper for PyTorch as well as TensorFlow. When we install Keras, it automaticaly installs TensorFlow.  \n",
    "\n",
    "We used DIY (hand-built) models to understand the concepts and also used SKLearn models.  \n",
    "In deep learning, DIY modeling gets more complicated.  \n",
    "We'll use Keras\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e381badb2fee20",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Google Tensorflow and Pytorch both help in modeling deep learning   \n",
    "Keras is a wrapper over TensorFlow.   \n",
    "\n",
    "#### Tensor   \n",
    "Tensor is the backbone of the PyTorch and TensorFlow models.   \n",
    "Tensor data structures allow us to handle multi-dimensional arrays of a uniform data type and perform mathematical operations on them.   \n",
    "It is similar to NumPy arrays. These have different ranks that represent the scalars (0D), vectors (1D), matrices (2D), or higher-dimensional arrays (nD).  \n",
    "They have various data types like floating-point numbers (float32, float64), integers (int32, int64), and others, which makes them flexible.  \n",
    "\n",
    "Numpy arrays are more general purpose and tensors focus on deep learning.    \n",
    "\n",
    "##### Tensors over Numpy    \n",
    "1. More support for Deep Learning   \n",
    "2. Built-in automatic differentiation function   \n",
    "3. Directly supports GPU accelerated computation   \n",
    "4. Supports automatic memory management   \n",
    "5. Has native support for PyTorch deep learning models   \n",
    "6. Parellal operations in CPUs and GPUs  \n",
    "7. Tensors are immutable    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182d85cd7b9df84",
   "metadata": {},
   "source": [
    "**Convolutional layer** applies filters to the input image to extract features.  \n",
    "\n",
    "![](../Figures/cnn-5.PNG)\n",
    "\n",
    "![](../Figures/cnn_cat.PNG)\n",
    "\n",
    "**Pooling layer** downsamples the image to reduce computation by reducing the dimension.   \n",
    "    E.g., Max pooling selects the maximum element from the region of the feature map covered by the filter. Thus, the output after max-pooling layer would be a feature map containing the most prominent features of the previous feature map.    \n",
    "    Average pooling computes the average of the elements present in the region of feature map covered by the filter.      \n",
    "\n",
    "1. Dimensionality reduction: Pooling layers reduce the spatial dimensions of the feature maps, reducing the computational cost. Avoids overfitting.     \n",
    "2. Translation invariance: Position of an object in the image does not affect the classification result, as the same features are detected regardless of the position of the object.   \n",
    "3. Feature selection: Pooling layers select the most important features from the input. Max pooling selects the most salient features and average pooling preserves more information.\n",
    "\n",
    "**Dense layer** makes the final prediction.   \n",
    "Neurons of the layer are connected to every neuron of its preceding layer.   \n",
    "The network learns the optimal filters through backpropagation and gradient descent.   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad71e98c05944eec",
   "metadata": {},
   "source": [
    "1. Continuous reduction of dimensions from the input to output layer.  This progressively reduces the computation.  \n",
    "2. The most common activation function in CNN is Rectified Linear function.\n",
    "    A neuron that uses it is called Rectified Linear Unit (ReLU)\n",
    "   $$f(x) = argmax(0,x)\\ OR\\ \\ 0,\\ for\\ x < 0\\  and\\  1,\\  for\\  x\\  \\ge\\  0 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faaf90a09f04c4",
   "metadata": {},
   "source": [
    "#### The Dropout Layer or Dropout Regularisation     \n",
    "The Dropout layer is a mask that nullifies the contribution of some neurons towards the next layer and leaves unmodified all others.  \n",
    "We can apply a Dropout layer to the input vector, in which case it nullifies some of its features; but we can also apply it to a hidden layer, in which case it nullifies some hidden neurons.  \n",
    "\n",
    "Dropout layers prevent overfitting on the training data.  \n",
    "```\n",
    "    model.add(dense(32))\n",
    "    model.add(dropout(0.5))\n",
    "    model.add(dense(1))\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06dfe7f6-2ab8-4c7a-8880-763d12191557",
   "metadata": {},
   "source": [
    "![](../Figures/activation_functions.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663f0d147c68c09f",
   "metadata": {},
   "source": [
    "#### Convolutional Neural Network (CNN)  \n",
    "CNN is designed to process and analyze data with grid-like topologies, e.g., images and videos.  \n",
    "A multi-layered filter that processes images to extract meaningful features and make predictions.  \n",
    "MNIST images of handwritten digits -> apply a series of filters over the image, gradually extracting more and more complex features. The first filters detect simple features like edges and lines, while later filters detect more complex patterns, such as shapes and digits.   \n",
    "\n",
    "1. **Convolutional Layers**: These layers apply filters (kernels) to the image. Each filter slides over the image, computing a dot product between the filter and the pixels it covers. This process generates a new feature map, which highlights specific patterns in the image. The process is repeated multiple times with different filters, creating a set of feature maps that capture different aspects of the image.  \n",
    "2. **Pooling Layers**: Pooling layers perform a downsampling operation on the feature maps, reducing the spatial dimensions of the data while retaining important features. This helps to reduce computational complexity and prevent overfitting. The most common type of pooling is max pooling, which selects the maximum value from a small neighborhood of pixels.  \n",
    "3. **Fully Connected Layers**: They connect every neuron in one layer to every neuron in the next layer. The output of the convolutional and pooling layers is flattened and passed through one or more fully connected layers, allowing the network to make a final prediction, such as recognizing the digit in the image.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e937aa020c21e1",
   "metadata": {},
   "source": [
    "### Not in Syllabus   \n",
    "#### Recurrent Neural Network (RNN)   \n",
    "RNNs process sequential data like time series, speech, and natural language.  Processes information one element at a time, allowing it to “remember” information from previous elements to make predictions about the next element. E.g., generate the next word in a  sequence,  using the information from previous words to predict the next word.\n",
    "\n",
    "Information flows from one time step to the next. The recurrent connection within a neuron  “remembers” information from the previous time step.\n",
    "\n",
    "1. **Input Layer** takes in the information at each time step, such as a word in the sequence.  \n",
    "2. **Recurrent Layer** processes the information from the input layer, using the recurrent connections to “remember” information from previous time steps. The layer contains a set of neurons, each with a recurrent connection to itself and a connection to the input at the current time step.  \n",
    "3. **Output Layer** generates a prediction based on the information processed by the recurrent layer. In the case of generating the next word in a sequence, the output layer would predict the most likely word to follow the previous words in the sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d29c0d1d6ad40a",
   "metadata": {},
   "source": [
    "#### Batch Normalisation   \n",
    "Batch Norm is a normalization technique done between the layers of a Neural Network instead of in the raw data.  \n",
    "It is done along mini-batches instead of the full data set.  \n",
    "It serves to speed up training and use higher learning rates, making learning easier.  \n",
    "\n",
    "```\n",
    "model = Sequential([\n",
    "    Dense(16, input_shape=(1,5), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dense(32, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dense(2, activation='softmax')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9033d6e831934bbe",
   "metadata": {},
   "source": [
    "#### Generative Adversarial Networks (GAN)  \n",
    "GAN uses two neural networks, a generator and a discriminator, to create new, realistic data. Imagine GANs as two rival artists, one creating fake art and the other trying to distinguish between real and fake.\n",
    "\n",
    "The goal of GANs is to generate high-quality, realistic data samples in various domains, such as images, audio, and text. The generator network creates new samples, while the discriminator network evaluates the authenticity of the generated samples. The two networks are trained simultaneously, in an adversarial manner, with the generator attempting to produce more realistic samples and the discriminator becoming better at detecting fakes.\n",
    "\n",
    "**Generator** takes a random noise vector as input and generates an output sample, such as an image or a sentence. It is trained to produce more realistic samples by minimizing a loss function that measures the difference between the generated samples and the real data.\n",
    "  \n",
    "**Discriminator** network evaluates the authenticity of the generated samples. It takes a sample as input and outputs a probability indicating whether the sample is real or fake. The discriminator is trained to distinguish between real and fake samples by maximizing a loss function that measures the difference between the probability of real and generated samples.   \n",
    "\n",
    "The adversarial nature of GANs arises from the competition between the generator and discriminator. The generator tries to produce more realistic samples to fool the discriminator, while the discriminator tries to improve its ability to distinguish real from fake samples. This process continues until the generator produces high-quality, realistic data that can’t be easily distinguished from real data.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a079a32c339c13",
   "metadata": {},
   "source": [
    "#### Transformers  \n",
    "Transformers are widely used in natural language processing (NLP) tasks, such as translation, text classification, and question-answering. Introduced in “Attention Is All You Need” by Vaswani et al. in 2017.  \n",
    "\n",
    "As a sophisticated language model it processes text by breaking it down into smaller pieces and analyzing their relationships. This model can then generate coherent and fluent responses to a wide range of queries.  \n",
    "\n",
    "Each layer contains two main components:\n",
    "1. **Self-Attention Mechanism** allows the model to analyze the relationships between different parts of the input text. It works by assigning a weight to each word in the input sequence, indicating its relevance to the current context. This allows the model to focus on important words and downplay the importance of less relevant ones.   \n",
    "2. **Feed-Forward Neural Networks** are multi-layer perceptrons that process the output of the self-attention mechanism. They are responsible for learning complex relationships between the words in the input text.   \n",
    "\n",
    "The key innovation of transformers is the use of self-attention mechanisms, which allow the model to efficiently process long sequences of text without the need for expensive recurrent or convolutional operations. Computationally efficient and effective for a wide range of NLP tasks.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87a62585c0e8d9c",
   "metadata": {},
   "source": [
    "#### Encoder-Decoder architectures  \n",
    "They are popular in natural language processing (NLP) tasks, often used for sequence-to-sequence problems, such as machine translation, where the goal is to convert input text in one language (source) to its corresponding text in another language (target).  \n",
    "1. **Encoder** takes the input sequence (source text) and processes it sequentially, generating a compact representation, often referred to as the “context vector” or “contextual embedding.” This representation summarizes the input sequence and contains information about its syntax, semantics, and context. The encoder can be a recurrent neural network (RNN) or a transformer, depending on the specific task and implementation.  \n",
    "2. **Decoder**  takes the context vector generated by the encoder and generates the output sequence (target text) one element at a time. The decoder is typically a recurrent neural network or a transformer, similar to the encoder. It generates the output sequence by predicting the next word in the target sequence based on the previous words and the information contained in the context vector.  \n",
    "\n",
    "During training, the decoder receives the true target sequence, and its goal is to predict the next word in the sequence. During inference (when the model is generating a response), the decoder receives the generated text up to that point and uses it to predict the next word."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
