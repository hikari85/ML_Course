{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d56f3c2568145075",
   "metadata": {},
   "source": [
    "#### Model Evaluation   \n",
    "- confusion matrix,   \n",
    "- accuracy,  \n",
    "- precision,   \n",
    "- recall,   \n",
    "- F1-Score,   \n",
    "- cross validation,   \n",
    "- Area under curve,   \n",
    "- Gradient Boosting.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5fc5a586d95148",
   "metadata": {},
   "source": [
    "#### AUC-ROC curve   \n",
    "The AUC-ROC curve, or Area Under the Receiver Operating Characteristic curve,  \n",
    "is a graphical representation of the performance of a binary classification model     \n",
    "at various classification thresholds.   \n",
    "It assesses the ability of a model to distinguish between two classes.  \n",
    "\n",
    "**True Positive Rate** or Sensitivity = $\\frac{True\\ Positives}{True\\ Positives + False\\ Negatives}$\n",
    "\n",
    "**False Positive Rate** = $\\frac{False\\ Positives}{False\\ Positives + True\\ Negatives}$  \n",
    "\n",
    "**Specificity** = $\\frac{True\\ Negatives}{False\\ Positives + True\\ Negatives}$  \n",
    "\n",
    "False Positive Rate = 1 - Specificity.   \n",
    "\n",
    "\n",
    "- ROC Curves summarize the trade-off between the true positive rate and false positive rate  \n",
    "    for a predictive model using different probability thresholds.  \n",
    "    It is a plot of the false positive rate (x-axis) versus the true positive rate (y-axis)    \n",
    "    for a number of different candidate threshold values between 0.0 and 1.0.  \n",
    "    It plots the false alarm rate versus the hit rate.  \n",
    "- Precision-Recall curves summarize the  \n",
    "    trade-off between the true positive rate and the positive predictive value  \n",
    "    for a predictive model using different probability thresholds.   \n",
    "- ROC curves are appropriate when the observations are balanced between each class,  \n",
    "    whereas precision-recall curves are appropriate for imbalanced datasets.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc2157b7b0ed4f0",
   "metadata": {},
   "source": [
    "1. ROC curves of different models can be compared directly in general or for different thresholds.  \n",
    "2. AUC can be used as a summary of the model skill.  \n",
    "\n",
    "- Smaller values on the x-axis of the plot indicate lower false positives and higher true negatives.  \n",
    "- Larger values on the y-axis of the plot indicate higher true positives and lower false negatives.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afac6f67-6dd2-4907-a196-d4222c55f671",
   "metadata": {},
   "source": [
    "#### skLearn predict() vs predict_proba()   \n",
    "The `predict()` method is used to predict a category for a set of input features.  \n",
    "It returns a discrete value that can be directly assigned to each input feature.  \n",
    "\n",
    "The `predict_proba()` method returns the predicted probabilities of the input features for each category.  \n",
    "This is useful when we also want to know the model's confidence in its prediction.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e7ca39-5594-43aa-9db7-86116dcac7b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "iris_data = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8aed99-4744-4c84-93e1-56081b41dd26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = iris_data.data\n",
    "y = iris_data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=4) # random_state=42\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "predicted_labels = model.predict(X_test)\n",
    "predicted_probabilities = model.predict_proba(X_test)\n",
    "\n",
    "print(f\"\\nroc_auc_score: {roc_auc_score(y_test, predicted_probabilities, multi_class='ovr')}\\n\")  \n",
    "\n",
    "print(\"Label argmax    max of probabilities\")\n",
    "for res in zip(predicted_labels, predicted_probabilities):\n",
    "    probs = res[1]\n",
    "    print(f\"  {res[0]} {np.argmax(res[1]):6}      {round(max(probs), 2)}   {probs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612cf4669e695158",
   "metadata": {},
   "source": [
    " ##### ROC curve and ROC AUC for a Logistic Regression model on a small test problem.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0b64590439d003",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5663f11-7b2c-4a13-8f07-737362d15c09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T10:43:17.740946900Z",
     "start_time": "2024-04-14T10:43:17.288458900Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_auc(model, X_test, y_test):\n",
    "    \n",
    "    # generate a no skill prediction (majority class)\n",
    "    ns_probs = [0 for _ in range(len(y_test))] # no skills probability\n",
    "    \n",
    "    lr_probs = model.predict_proba(X_test)     # logistics regression probability\n",
    "    lr_probs = lr_probs[:, 1]                  # probabilities for positive outcome only\n",
    "\n",
    "    # calculate and display scores\n",
    "    ns_auc = roc_auc_score(y_test, ns_probs)   \n",
    "    lr_auc = roc_auc_score(y_test, lr_probs)   \n",
    "    print(f'\\nNo Skill: ROC AUC = {ns_auc:.3f}')\n",
    "    print(f'Logistic: ROC AUC = {lr_auc:.3f}')\n",
    "\n",
    "    # calculate roc curves:  fpr = flase positive rate, tpr = true positive rate\n",
    "    ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)\n",
    "    lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)\n",
    "\n",
    "    # plot the roc curve for the model\n",
    "    plt.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n",
    "    plt.plot(lr_fpr, lr_tpr, marker='.', label='Logistic')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a074fc2-d791-454a-8367-8a7f73656777",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T10:43:17.740946900Z",
     "start_time": "2024-04-14T10:43:17.288458900Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# generate 2 class dataset\n",
    "X, y = make_classification(n_samples=1000, n_classes=2, random_state=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=2)\n",
    "\n",
    "model = LogisticRegression(solver='lbfgs')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "plot_auc(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa160a41-a8cc-444f-88dd-d9d9478ca8be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T10:43:17.740946900Z",
     "start_time": "2024-04-14T10:43:17.288458900Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# generate 2 class dataset\n",
    "X, y = make_classification(n_samples=1000, n_classes=2, random_state=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=2)\n",
    "\n",
    "model = LogisticRegression(solver='sag')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "plot_auc(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404c6b7801e4bc8f",
   "metadata": {},
   "source": [
    "#### Precision-Recall Curves     \n",
    "In iformation retrieval (finding documents based on queries) we measure precision and recall. These measures are also useful in applied machine learning for evaluating binary classification models.\n",
    "\n",
    "Positive predictive value or $Precision = \\frac{True\\ Positives}{True\\ Positives + False\\ Positives}$   \n",
    "\n",
    "Recall or $Sensitivity =  \\frac{True\\ Positives}{True\\ Positives + False\\ Negatives}$   \n",
    "\n",
    "Reviewing both precision and recall is useful in cases where there is an imbalance in the observations between the two classes. Specifically, there are many examples of no event (class 0) and only a few examples of an event (class 1). It is only concerned with the correct prediction of the minority class, class 1.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a44911e-4c0e-4597-a88c-a6fe33b1b7ce",
   "metadata": {},
   "source": [
    "##### sk-Learn Solvers   \n",
    "1. newton-cg   \n",
    "2. lbfgs (Limited-memory Broyden–Fletcher–Goldfarb–Shanno Algorithm)    \n",
    "3. liblinear (A Library for Large Linear Classification)\n",
    "4. sag (Stochastic Average Gradient)    \n",
    "5. saga   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7d022d-96a2-4d84-b82d-43524a70f83b",
   "metadata": {},
   "source": [
    "#### Plot precision_recall_curve for the model   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca56b7c7-dda2-425c-8844-2e21b95fddc7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T10:34:58.342180700Z",
     "start_time": "2024-04-14T10:34:57.867152600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_precision_recall(model, X_test, y_test):\n",
    "    lr_probs = model.predict_proba(X_test)\n",
    "    # keep probabilities for the positive outcome only\n",
    "    lr_probs = lr_probs[:, 1]\n",
    "\n",
    "    yhat = model.predict(X_test)\n",
    "    lr_precision, lr_recall, _ = precision_recall_curve(y_test, lr_probs)\n",
    "    lr_f1, lr_auc = f1_score(y_test, yhat), auc(lr_recall, lr_precision)\n",
    "    print(f'Logistic: f1 = {lr_f1:.3f}   auc = {lr_auc:.3f}')\n",
    "\n",
    "    # plot the precision-recall curves\n",
    "    no_skill = len(y_test[y_test==1]) / len(y_test)  # average value\n",
    "    plt.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill')\n",
    "\n",
    "    plt.plot(lr_recall, lr_precision, marker='.', label='Logistic')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507f9824-8d63-4630-a452-7b1d7caa95ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T10:34:58.342180700Z",
     "start_time": "2024-04-14T10:34:57.867152600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "plot_precision_recall(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa511aa0a8140585",
   "metadata": {},
   "source": [
    "- Use ROC curves when there are roughly equal numbers of observations for each class.\n",
    "- Use Precision-Recall curves when there is a moderate to large class imbalance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efd6b39-6ef2-421a-8ba6-1df610949ec2",
   "metadata": {},
   "source": [
    "#### Task   \n",
    "Draw AUC-ROC curves for  \n",
    "- a classifier with Sonar data.  \n",
    "- a male/female classifier based on height, weight, collar size, shoulder and waist measures.   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52228bba-1396-444e-9f03-735fc288ebf8",
   "metadata": {},
   "source": [
    "#### classify Sonar data   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c5a2e6-fb30-4595-813d-1e688eacdec6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c55afac-336b-41d3-891e-f4527a0555b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('../Data/sonar.csv', header = None)\n",
    "target = 60\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aad1f96-325a-46f7-8f23-8231d31d48be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a37ed1-fb2b-4f52-9fb3-39d96e22de6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset.replace({'R': 0, 'M': 1}, inplace=True)  # encode labels   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6055f48f-60b4-46b7-ad4d-fde2ca01ad39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = dataset.drop(columns = target, axis = 1)\n",
    "y = dataset[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68871c25-3c89-44ba-a82b-14fabd6a458a",
   "metadata": {},
   "source": [
    "#### shuffle or stratify   \n",
    "Stratify parameter makes a split so that the proportion of values in the sample produced will be the same as the proportion of values provided by parameter stratify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38478e1a-c838-40de-8c20-9b28cad028e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, test_size = 0.1, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb29d0b5-8325-44b7-8dee-e817b19fa219",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"y_test: {y_test.value_counts()}\")\n",
    "print(f\"y_train: {y_train.value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6452052f-0a1b-4234-a996-da8c0022cd19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "# model = LogisticRegression(solver='lbfgs')\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825a9890-50d6-48de-af44-6c08a48a8bf8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "train_accuracy_score = accuracy_score(y_train, model.predict(X_train))\n",
    "test_accuracy_score = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy score on training data: {train_accuracy_score}')\n",
    "print(f'Accuracy score on test data    : {test_accuracy_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2801c220-29b2-44fb-951f-1632dc4d2abd",
   "metadata": {},
   "source": [
    "#### Plot AUC  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcb9d33-1304-4c3d-bff9-7b0890f8daaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_auc(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18d2407-119d-4168-b698-dce6dbf139ad",
   "metadata": {},
   "source": [
    "#### Plot Precision-Recall Curve  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fd6376-fc4d-4713-bb8b-efd46aa61c18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_precision_recall(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdaa2d12-2713-4a74-8dfa-4a1a43dd02b6",
   "metadata": {},
   "source": [
    "#### Student Data   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a70b3d-3b27-4e51-8395-fc110b991ccc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cols = ['Height_cm', 'Weight_Kg', 'Sex']\n",
    "df_std = pd.read_excel('../Data/Seven Schools.xlsx', sheet_name='all_Schools', usecols=cols)\n",
    "\n",
    "df_std = df_std[cols]                           # re-order columns\n",
    "df_std.Sex = df_std.Sex.str.strip()             # remove leading and trailing spaces\n",
    "df_std.replace({'F': 0, 'M': 1}, inplace=True)  # encode labels   \n",
    "df_std.Sex = df_std.Sex.astype('int')\n",
    "df_std.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c56abb-4740-47b9-aed9-f59f32f5c142",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = df_std[['Height_cm', 'Weight_Kg']].values\n",
    "y = df_std['Sex'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 1)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "train_accuracy_score = accuracy_score(y_train, model.predict(X_train))\n",
    "test_accuracy_score = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy score on training data: {train_accuracy_score}')\n",
    "print(f'Accuracy score on test data    : {test_accuracy_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797b3662-febe-491e-8f7e-6ad0343c7df1",
   "metadata": {},
   "source": [
    "#### AUC   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb8f0eb-8755-4ce3-b127-3f92983cf7ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_auc(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089a5dbe-7061-4474-bfa3-b199f8522453",
   "metadata": {},
   "source": [
    "#### Plot Precision-Recall Curve  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4354810-67e6-4aa4-9a5e-0e3d9d81db50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_precision_recall(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f6f27d-7603-4a98-b00c-85b385620602",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9edf2ba5-581a-4cbd-b0a2-abde6cc53424",
   "metadata": {},
   "source": [
    "#### Lower F1 scores with reduced features   \n",
    "AUC reduces with lower accuracy   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59880c9a-7732-44ad-9b7b-2387523d0c86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cols = ['Weight_Kg', 'Sex']\n",
    "df_std = pd.read_excel('../Data/Seven Schools.xlsx', sheet_name='all_Schools', usecols=cols)\n",
    "\n",
    "df_std = df_std[cols]                           # re-order columns\n",
    "df_std.Sex = df_std.Sex.str.strip()             # remove leading and trailing spaces\n",
    "df_std.replace({'F': 0, 'M': 1}, inplace=True)  # encode labels   \n",
    "df_std.Sex = df_std.Sex.astype('int')\n",
    "\n",
    "X = df_std[['Weight_Kg']].values\n",
    "y = df_std['Sex'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 1)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "train_accuracy_score = accuracy_score(y_train, model.predict(X_train))\n",
    "test_accuracy_score = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy score on training data: {train_accuracy_score}')\n",
    "print(f'Accuracy score on test data    : {test_accuracy_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee609a8-0c84-4bce-a2e5-c55fdfb0ec4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_auc(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5aef27-bcb3-423c-806f-60ac5c411523",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_precision_recall(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eccfa76-62e5-4f4e-be72-b9aa4ffa9bcc",
   "metadata": {},
   "source": [
    "#### With Height as feature     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299a25c4-53a2-4893-af7d-79776d086f58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cols = ['Height_cm', 'Sex']\n",
    "df_std = pd.read_excel('../Data/Seven Schools.xlsx', sheet_name='all_Schools', usecols=cols)\n",
    "\n",
    "df_std = df_std[cols]                           # re-order columns\n",
    "df_std.Sex = df_std.Sex.str.strip()             # remove leading and trailing spaces\n",
    "df_std.replace({'F': 0, 'M': 1}, inplace=True)  # encode labels   \n",
    "df_std.Sex = df_std.Sex.astype('int')\n",
    "\n",
    "X = df_std[['Height_cm']].values\n",
    "y = df_std['Sex'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 1)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "train_accuracy_score = accuracy_score(y_train, model.predict(X_train))\n",
    "test_accuracy_score = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy score on training data: {train_accuracy_score}')\n",
    "print(f'Accuracy score on test data    : {test_accuracy_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b585696b-ee41-4880-9299-a50e94129379",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_auc(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123bb352-3d29-499a-9862-b89291a45f66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_precision_recall(model, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
