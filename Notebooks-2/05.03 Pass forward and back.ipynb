{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efdddedf-8191-4f87-a3cb-1312e81ba296",
   "metadata": {},
   "source": [
    "### Backpropagation   \n",
    "\"Backward propagation of errors\" in supervised learning minimizes errors in predictions made by neural networks. Using chain-rule application it computes gradients of loss functions in relation to model parameters.\n",
    "\n",
    "1. Forward pass  \n",
    "    An input is passed through the neural network layers to generate a prediction. The prediction is then compared with the real label to calculate an error.  \n",
    "2. Backward pass  \n",
    "    To adjust the weights and minimise the error, the backward pass starts with this error and works backward through the network. The neural network then, gradually improves its prediction through iterative adjustments using optimization algorithms such as gradient descent.    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bd1fe6-d62f-47e6-bbab-0f5157a14aed",
   "metadata": {},
   "source": [
    "#### Chain Rule   \n",
    "The chain rule describes how to compute the derivative of composite functions when functions are nested within one another.\n",
    "\n",
    "E.g., two functions $y = g(u)$ and $u = f(x)$ are composed to form $y = g(f(x))$.   \n",
    "The chain rule provides a formula to compute the derivative of $y$ with respect to $x$ by considering the “intermediate” function $u$.\n",
    "\n",
    "If $y$ is a function of $u$ and $u$ is a function of $x$, then the derivative of $y$ with respect $x$ is given by:\n",
    "$$\\frac{dx}{dy} = \\frac{du}{dy}\\ .\\ \\frac{dx}{dv} $$\n",
    "\n",
    "This can be extended to two functions (or more). Suppose y is a function of u, u is a function of v, and v is a function of x. Then:​\n",
    "$$\\frac{dx}{dy} = \\frac{du}{dy}\\ .\\ \\frac{dv}{du}\\ .\\ \\frac{dx}{dv} $$\n",
    "\n",
    "##### Example   \n",
    "Given the functions:   \n",
    "$$u(x) = 3x + 2$$\n",
    "$$y(u) = u^2$$\n",
    "\n",
    "\n",
    "Find the derivative of $y$ - $\\frac{dx}{dy}$ - with respect to $x$.  \n",
    "\n",
    "Step 1: \n",
    "$$u(x) = 3x + 2$$\n",
    "$$\\frac{dx}{du} = 3$$\n",
    "\n",
    "\n",
    "\n",
    "Step 2:  \n",
    "$$y(u) = u^2$$   \n",
    "$$\\frac{dy}{du} = 2u$$   \n",
    "\n",
    "\n",
    "Step 3: Apply the Chain Rule    \n",
    "$$\\frac{dx}{dy} = \\frac{du}{dy}\\ .\\ \\frac{dx}{du}$$\n",
    "\n",
    "\n",
    "Step 4: Plugging in what we found: $\\frac{dy}{du} = 2u\\ . 3$ and $\\frac{dy}{dx} = 6u$\n",
    "\n",
    "\n",
    "Step 5: Replace u with the original function of x:\n",
    "$$\\frac{dx}{dy} =  18x + 12$$\n",
    "\n",
    "This result describes how a small change in x affects y through its effect on u."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
