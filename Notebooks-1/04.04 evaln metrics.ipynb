{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76388d47-4993-4315-a020-c459c256f72e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from random import randint\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import tree\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6baea6-6655-4194-b7e8-9e6148522218",
   "metadata": {},
   "source": [
    "tp = true positive   \n",
    "fp = false positive   \n",
    "tn = true negative      \n",
    "fn = false negative   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5444119-d339-4732-9b06-e8285db4cf21",
   "metadata": {},
   "source": [
    "$$precision = \\frac{tp}{tp + fp}$$\n",
    "\n",
    "$$recall (sensitivity) = \\frac{tp}{tp + fn}$$\n",
    "\n",
    "There is often an inverse relationship between precision and recall.   \n",
    "F1 score combines precision and recall into a single metric\n",
    "\n",
    "$$F1 = \\frac{2}{\\frac{1}{P} +\\frac{1}{R} } = \\frac{2 * P*R}{{P} +{R} }$$    \n",
    "\n",
    "The **harmonic mean** is the equivalent of the arithmetic mean for reciprocals of quantities that should be averaged by the arithmetic mean.  \n",
    "With the harmonic mean, we transform all the numbers to the “averageable” form (by taking the reciprocal),  \n",
    "take their arithmetic mean and then transform the result back to the original representation (by taking the reciprocal again).   \n",
    "\n",
    "Example: we travel 10 km at 60 km/h, then another 10 km at 20 km/h, what is our average speed?   \n",
    "Harmonic mean = $\\frac{2}{\\frac{1}{60} + \\frac{1}{20}} = \\frac{2*60*20}{60+20} = 30 kmph$\n",
    "\n",
    "##### Check   \n",
    "1. 10 km at 60 km/h takes 10 minutes.  \n",
    "2. another 10 km at 20 km/h takes 30 minutes.  \n",
    "3. therefore, the total 20 km takes 40 minutes, which is 30 km per hour.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "71a3986c-6235-423b-b590-f0f1f2664117",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.0"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(2*60*20)/(60+20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ae3aabe-0106-4564-838a-48b6d900942a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy Score: 0.97\n",
      "\n",
      "Actual flower types: Counter({'Iris-versicolor': 13, 'Iris-setosa': 11, 'Iris-virginica': 6})\n",
      "\n",
      "Confusion Matrix:\n",
      "            setosa  versicolor  virginica\n",
      "setosa          11           0          0\n",
      "versicolor       0          12          1\n",
      "virginica        0           0          6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../Data/iris_data.csv')\n",
    "\n",
    "array = df.values\n",
    "X = array[:,0:4]\n",
    "y = array[:,4]\n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(X, y, test_size=0.20, random_state=1)\n",
    "\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf.fit(X_train,Y_train)\n",
    "\n",
    "predictions = clf.predict(X_validation)\n",
    "\n",
    "print(f\"\\nAccuracy Score: {accuracy_score(Y_validation, predictions):.2}\\n\")\n",
    "print(f\"Actual flower types: {Counter(Y_validation)}\\n\")\n",
    "print(\"Confusion Matrix:\")\n",
    "df = pd.DataFrame(confusion_matrix(Y_validation, predictions), \n",
    "                  index=['setosa','versicolor','virginica'], \n",
    "                  columns=['setosa','versicolor','virginica'])\n",
    "print(df); print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edd2175-98ae-46af-a582-6158ce690848",
   "metadata": {},
   "source": [
    "A different **random_state** setting will change the accuracy scores.   \n",
    "In the above case:  \n",
    "##### setosa   \n",
    "tp = 11; fp = 0, fn = 0;  \n",
    "precision = $\\frac{11}{11+0}$; recall = $\\frac{11}{11+0}$;  F1-score = $\\frac{2 (1 * 1)}{1 + 1}$   \n",
    "\n",
    "#####  versicolor     \n",
    "tp = 12; fp = 0, fn = 1;  \n",
    "precision = $\\frac{12}{12+0} = 1$; recall = $\\frac{12}{12+1} = 0.92$;  F1-score = $\\frac{2 (1 * 0.92)}{1 + 0.92} = 0.96$   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "125f428e-45a9-46d4-9b50-ec49fc0c2a86",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setosa      Precision: 1.0;  Recall: 1.0;  F1-Score: 1.0\n",
      "versicolor  Precision: 1.0;  Recall: 0.92; F1-Score: 0.96\n",
      "virginica   Precision: 0.86; Recall: 1.0;  F1-Score: 0.92\n"
     ]
    }
   ],
   "source": [
    "print(f\"setosa      Precision: {11/11};  Recall: {round(11/11,2)};  F1-Score: {round(2 * (11/11) * (11/11)/(11/11 + 11/11), 2)}\")\n",
    "print(f\"versicolor  Precision: {12/12};  Recall: {round(12/13,2)}; F1-Score: {round(2 * (12/12) * (12/13)/(12/12 + 12/13), 2)}\")\n",
    "print(f\"virginica   Precision: {round(6/7, 2)}; Recall: {round(6/6,2)};  F1-Score: {round(2 * (6/7) * 1/(6/7 + 1), 2)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "40d08127-4e11-43cd-a349-7eb806062cc3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Macro Avg: 0.95; weighted Avg: 0.97\n",
      "Recall Macro Avg:    0.97; weighted Avg: 0.97\n",
      "F1 Score Macro Avg:  0.96; weighted Avg: 0.97\n"
     ]
    }
   ],
   "source": [
    "print(f\"Precision Macro Avg: {round(2.86/3, 2)}; weighted Avg: {round((11 + 13 + 6*0.86)/30, 2)}\")\n",
    "print(f\"Recall Macro Avg:    {round(2.92/3, 2)}; weighted Avg: {round((11 + 13*0.92 + 6)/30, 2)}\")\n",
    "print(f\"F1 Score Macro Avg:  {round((1+0.96+0.92)/3, 2)}; weighted Avg: {round((11 + 13*0.96 + 6*0.92)/30, 2)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4c9c60f-7fe1-46bc-8b56-f4dee8733e43",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        11\n",
      "Iris-versicolor       1.00      0.92      0.96        13\n",
      " Iris-virginica       0.86      1.00      0.92         6\n",
      "\n",
      "       accuracy                           0.97        30\n",
      "      macro avg       0.95      0.97      0.96        30\n",
      "   weighted avg       0.97      0.97      0.97        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report:\")\n",
    "print(classification_report(Y_validation, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e38bbf5c-fe8b-4ae1-b4d9-476766d2fef3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(Y_validation, predictions) #, normalize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5ac30e-63a1-4501-b6a0-c95b30245389",
   "metadata": {},
   "source": [
    "##### Accuracy:  \n",
    "Measure of all the correctly identified cases.  \n",
    "$$\\frac{tp + tn}{tp+fp+tn+fn}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7076db98-806e-4156-8c88-5d40a9b37291",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculated Accuracy Score: 0.9666666666666667\n",
      "SciKit Accuracy Score:     0.9666666666666667\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nCalculated Accuracy Score: {(11+12+6)/30}\")\n",
    "print(f\"SciKit Accuracy Score:     {accuracy_score(Y_validation, predictions)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5b4faf-3234-4f4c-8d3f-e16da7e72694",
   "metadata": {},
   "source": [
    "##### normalize, default=True\n",
    "If False, return the number of correctly classified samples.   \n",
    "Otherwise, return the fraction of correctly classified samples.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28917ab8-5cf4-498a-b3a0-4c93745bec65",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of correct classifications:   29\n",
      "Fraction of correct classifications: 0.97\n"
     ]
    }
   ],
   "source": [
    "print(f\"Count of correct classifications:   {accuracy_score(Y_validation, predictions, normalize=False)}\")\n",
    "print(f\"Fraction of correct classifications: {accuracy_score(Y_validation, predictions):.2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7448fcbe-e844-4fd1-a255-8e5080e21cc8",
   "metadata": {},
   "source": [
    "##### Accuracy score  \n",
    "True Positives and True negatives are more important.   \n",
    "Balanced class distribution.   \n",
    "##### F1-score   \n",
    "False Negatives and False Positives are crucial.    \n",
    "Imbalanced classes.  \n",
    "\n",
    "In real-life imbalanced class distribution is normal.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f64fa9-110a-4016-82d2-76cf6c22eb7c",
   "metadata": {},
   "source": [
    "##### Task   \n",
    "Change the random_state to create training and test sets.  \n",
    "See the reported confusion matrix and accuracy scores.  \n",
    "Calculate manually and verify.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343a132f-0c94-4cdd-8b07-d423a8533710",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1a935e-a525-4402-bdd0-150f33fa36f8",
   "metadata": {},
   "source": [
    "#### <u>$R^2$ Score for regression</u>   \n",
    "\n",
    "$MSE = \\frac{\\sum _i ^N (y_i – \\hat y_i)^2}{N}$   \n",
    "\n",
    "$RMSE = \\sqrt{MSE}$    \n",
    "\n",
    "$R^2 = \\frac{\\sum(y_i - \\hat y_i)^2}{\\sum(y_i - \\bar y_i)^2}$ = $\\frac{MSE}{variance}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a9f412bc-69bc-48d7-889f-04488820691a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6ef820e-c0dc-4802-bddc-e39553be9159",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score 0.9965\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('../Data/BSc22A_Student_Data.xlsx', usecols=['Height_cm', 'Weight_Kg'])\n",
    "df['BMI'] = df.Weight_Kg/(df.Height_cm/100)**2\n",
    "df = df.dropna()\n",
    "\n",
    "X_train = df.values[:,0:2]\n",
    "y_train = df.values[:,2]\n",
    "\n",
    "regressor = LinearRegression()\n",
    "bmi_model = regressor.fit(X_train, y_train)\n",
    "\n",
    "print(f\"R2 Score {bmi_model.score(X_train, y_train):.4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61f3d441-4ca6-4a78-a5d3-b529d5e1cb4b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score\n",
      "\tHt & Wt features:  0.9965\n",
      "\tWeight as feature: 0.7693\n",
      "\tHeight as feature: 0.02746\n"
     ]
    }
   ],
   "source": [
    "Ht_train =  df.values[:,0:1]\n",
    "Wt_train =  df.values[:,1:2]\n",
    "\n",
    "print(\"R2 Score\")\n",
    "bmi_model = regressor.fit(X_train, y_train)\n",
    "print(f\"\\tHt & Wt features:  {bmi_model.score(X_train, y_train):.4}\")\n",
    "\n",
    "wt_model = regressor.fit(Wt_train, y_train)\n",
    "print(f\"\\tWeight as feature: {wt_model.score(Wt_train, y_train):.4}\")\n",
    "\n",
    "ht_model = regressor.fit(Ht_train, y_train)\n",
    "print(f\"\\tHeight as feature: {ht_model.score(Ht_train, y_train):.4}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b9edd2-f94e-4c6b-833c-6900d094f19d",
   "metadata": {},
   "source": [
    "BMI is calcuated using height and weight of a person.  \n",
    "When one of the features is not used to train the model, accuracy reduces.  \n",
    "Effect of weight on BMI is higher than that of height."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56b4834-3e41-4b00-b0df-2953eed9dfa7",
   "metadata": {},
   "source": [
    "##### Task   \n",
    "Check the effect of adding other numeric parameters.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
