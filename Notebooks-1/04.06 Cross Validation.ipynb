{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dd4655b-4577-4682-af24-1a7f99a384ec",
   "metadata": {},
   "source": [
    "### Cross Validation   \n",
    "When adjusting models we aim to increase overall model performance on unseen data.  \n",
    "Hyperparameter tuning can lead to much better performance on test sets.  \n",
    "However, optimizing parameters to the test set can make the model to preform worse on unseen data.  \n",
    "To correct for this we can perform cross validation.   \n",
    "\n",
    "There are many methods to cross validation.  \n",
    "We will discuss _k-fold cross validation_ using a _DecisionTreeClassifier_.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e6b811f-2d78-44c5-8fec-593ddb800e6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import KFold, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd98a149-1bf9-4d32-8d6d-c22365fdd688",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "X, y = datasets.load_iris(return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce976ecd-5074-4f6d-8b5c-81cc979edbd0",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### K-Fold   \n",
    "The training data used in the model is split, into k number of smaller sets, to be used to validate the model.  \n",
    "The model is then trained on k-1 folds of training set.  \n",
    "The remaining fold is then used as a validation set to evaluate the model.  \n",
    "\n",
    "General procedure:   \n",
    "1. Shuffle the dataset randomly.\n",
    "2. Split the dataset into k groups\n",
    "3. For each unique group:  \n",
    "    - Take the group as a hold out or test data set  \n",
    "    - Take the remaining groups as a training data set   \n",
    "    - Fit a model on the training set and evaluate it on the test set   \n",
    "    - Retain the evaluation score and discard the model  \n",
    "    \n",
    "Summarize the skill of the model using the sample of model evaluation scores  \n",
    "\n",
    "![](../Figures/cross_validate.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262bcf92-c4c9-4d6b-8e87-b68fb3053c6f",
   "metadata": {},
   "source": [
    "![](../Figures/cross_validate_.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "686f6c5c-952d-45d2-899b-c4ed2f18b5f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "k_folds = KFold(n_splits = 5)\n",
    "scores = cross_val_score(clf, X, y, cv = k_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8327237-0945-4895-8feb-6cd640aeac86",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Scores:  [1.         1.         0.83333333 0.93333333 0.8       ]\n",
      "Average CV Score:  0.9133333333333333\n",
      "Number of CV Scores used in Average:  5\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "import pandas as pd\n",
    "# from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics \n",
    "\n",
    "# sample dataset  \n",
    "X, y = datasets.load_iris(return_X_y=True)\n",
    "\n",
    "# Create a classifier model and fit. \n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "k_folds = KFold(n_splits = 5)\n",
    "scores = cross_val_score(clf, X, y, cv = k_folds)\n",
    "\n",
    "print(\"Cross Validation Scores: \", scores)\n",
    "print(\"Average CV Score: \", scores.mean())\n",
    "print(\"Number of CV Scores used in Average: \", len(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d92cc39b-6fda-414d-a486-61bd13dee0f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "clf = clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d388eaf-0a34-4856-a400-53131b62efbd",
   "metadata": {},
   "source": [
    "Variations in Cross-Validation techniques\n",
    "1. K-Fold Cross-Validation\n",
    "2. Stratified K-Fold Cross-Validation\n",
    "3. Hold-Out based Validation\n",
    "4. Leave-One-Out Cross-Validation\n",
    "5. Group K-Fold Cross-Validation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
